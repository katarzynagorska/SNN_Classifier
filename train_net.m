function [net]= train_net(train_set,labels,hidden_neurons_count)
    %Opis: funkcja tworz¹ca i ucz¹ca sieæ neuronow¹
    %Parametry:
    %   train_set: zbiór ucz¹cy - kolejne punkty w kolejnych wierszach
    %   labels:    etykiety punktów - {-1,1}
    %   hidden_neurons_count: liczba neuronów w warstwie ukrytej
    %Wartoœæ zwracana:
    %   net - obiekt reprezentuj¹cy sieæ neuronow¹

    %inicjalizacja obiektu reprezentuj¹cego sieæ neuronow¹
        %Backpropagation networks have net.layers{i}.initFcn set to 'initnw', 
        %which calculates the weight and bias values for layer i 
        %using the Nguyen-Widrow initialization method.
    %funkcja aktywacji: neuronów z warstwy ukrytej - tangens hiperboliczny,
    %                   neuronu wyjœciowego - liniowa
    %funkcja ucz¹ca: gradient descent backpropagation - propagacja wsteczna
    %                   b³êdu    
    net=newff(train_set',labels',hidden_neurons_count,...
              {'tansig', 'purelin'},'traingd');
          
    rand('state',sum(100*clock));           %inicjalizacja generatora liczb 
                                            %pseudolosowych
    
	net=init(net);                          %inicjalizacja wag sieci
    net.trainParam.goal = 0.01;             %warunek stopu - poziom b³êdu
    net.trainParam.epochs = 100;            %maksymalna liczba epok
    net.trainParam.showWindow = false;      %nie pokazywaæ okna z wykresami
                                            %w trakcie uczenia
    net=train(net,train_set',labels');      %uczenie sieci
    
    %zmiana funkcji ucz¹cej na: Levenberg-Marquardt backpropagation
    net.trainFcn = 'trainlm';
    net.trainParam.goal = 0.01;             %warunek stopu - poziom b³êdu
    net.trainParam.epochs = 200;            %maksymalna liczba epok
    net.trainParam.showWindow = false;      %nie pokazywaæ okna z wykresami
                                            %w trakcie uczenia
    net=train(net,train_set',labels');      %uczenie sieci
    